{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import cpu_count\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5 # depends on time window\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "pose_vec_dim = 36 # depends on pose estimation model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0, 1, 2]\n",
    "num_class = len(class_names)\n",
    "lbl_dict = {class_name:idx for idx, class_name in enumerate(class_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './data/csv/result.csv'\n",
    "validate_csv_path = './data/csv/validate.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(csv_path,  index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_vec(x):\n",
    "    return np.array(re.split(',*',re.sub('^\\D\\D*|\\D*\\D$', '',re.sub('\\D', ',', str(x)))), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_data(X, Y, window):\n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    max_row = X.shape[0] - (X.shape[0] % window + 1)\n",
    "    i = window\n",
    "    while i < max_row:\n",
    "        new_x.append(X[i-window+1:i+1]-X[i-window:i])\n",
    "        new_y.append(Y[i])\n",
    "        i+=1\n",
    "    return np.array(new_x), np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(csv_path,  index_col=None)\n",
    "\n",
    "y = dataset.label.values\n",
    "X = np.stack(dataset.vec.apply(convert_vec).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler().fit(X)\n",
    "\n",
    "X = min_max_scaler.transform(X)\n",
    "\n",
    "X,y = shape_data(X,y,window)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(list(map(lbl_dict.get, y_train)), num_class)\n",
    "y_test = tf.keras.utils.to_categorical(list(map(lbl_dict.get, y_test)), num_class)\n",
    "\n",
    "#y_valid = y_test[:y_test.shape[0] // 3]\n",
    "#X_valid = X_test[:X_test.shape[0] // 3]\n",
    "\n",
    "#y_test = y_test[y_test.shape[0] // 3:]\n",
    "#X_test = X_test[X_test.shape[0] // 3:]\n",
    "\n",
    "#X_test = X_test.reshape(X_test.shape[0], pose_vec_dim, window)\n",
    "#X_train = X_train.reshape(X_train.shape[0], pose_vec_dim, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5931, 5, 36)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('min_max_scaler.pickle', 'wb') as f:\n",
    "    pickle.dump(min_max_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"../app/models/lstm_model.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 32)                8832      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 9,411\n",
      "Trainable params: 9,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, recurrent_dropout=0.5, input_shape=(window, pose_vec_dim)))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(class_names), activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ee60429af7e07a0a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ee60429af7e07a0a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port 6006 --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "371/371 [==============================] - 12s 28ms/step - loss: 1.0267 - accuracy: 0.4709 - val_loss: 0.9487 - val_accuracy: 0.5576\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.47671\n",
      "Epoch 2/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.9377 - accuracy: 0.5827 - val_loss: 0.8770 - val_accuracy: 0.6138\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.47671\n",
      "Epoch 3/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.8698 - accuracy: 0.6220 - val_loss: 0.8219 - val_accuracy: 0.6563\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.47671\n",
      "Epoch 4/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.8263 - accuracy: 0.6522 - val_loss: 0.7737 - val_accuracy: 0.6736\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47671\n",
      "Epoch 5/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.7920 - accuracy: 0.6684 - val_loss: 0.7523 - val_accuracy: 0.6783\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47671\n",
      "Epoch 6/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.7682 - accuracy: 0.6820 - val_loss: 0.7146 - val_accuracy: 0.7023\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.47671\n",
      "Epoch 7/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.7439 - accuracy: 0.6918 - val_loss: 0.6924 - val_accuracy: 0.7137\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47671\n",
      "Epoch 8/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.7169 - accuracy: 0.7086 - val_loss: 0.6730 - val_accuracy: 0.7271\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.47671\n",
      "Epoch 9/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.6937 - accuracy: 0.7140 - val_loss: 0.6557 - val_accuracy: 0.7318\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.47671\n",
      "Epoch 10/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.6731 - accuracy: 0.7275 - val_loss: 0.6350 - val_accuracy: 0.7381\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.47671\n",
      "Epoch 11/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.6551 - accuracy: 0.7393 - val_loss: 0.6207 - val_accuracy: 0.7495\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.47671\n",
      "Epoch 12/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.6350 - accuracy: 0.7468 - val_loss: 0.6219 - val_accuracy: 0.7448\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.47671\n",
      "Epoch 13/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.6261 - accuracy: 0.7500 - val_loss: 0.5983 - val_accuracy: 0.7688\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.47671\n",
      "Epoch 14/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.6087 - accuracy: 0.7609 - val_loss: 0.6020 - val_accuracy: 0.7574\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.47671\n",
      "Epoch 15/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.6052 - accuracy: 0.7609 - val_loss: 0.5890 - val_accuracy: 0.7684\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.47671\n",
      "Epoch 16/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5838 - accuracy: 0.7678 - val_loss: 0.5735 - val_accuracy: 0.7798\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.47671\n",
      "Epoch 17/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5770 - accuracy: 0.7769 - val_loss: 0.5697 - val_accuracy: 0.7774\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.47671\n",
      "Epoch 18/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5677 - accuracy: 0.7744 - val_loss: 0.5701 - val_accuracy: 0.7766\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.47671\n",
      "Epoch 19/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5554 - accuracy: 0.7830 - val_loss: 0.5578 - val_accuracy: 0.7884\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.47671\n",
      "Epoch 20/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5453 - accuracy: 0.7892 - val_loss: 0.5525 - val_accuracy: 0.7873\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.47671\n",
      "Epoch 21/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5399 - accuracy: 0.7872 - val_loss: 0.5528 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.47671\n",
      "Epoch 22/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5315 - accuracy: 0.7914 - val_loss: 0.5445 - val_accuracy: 0.7904\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.47671\n",
      "Epoch 23/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5150 - accuracy: 0.8024 - val_loss: 0.5469 - val_accuracy: 0.7916\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.47671\n",
      "Epoch 24/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5102 - accuracy: 0.8031 - val_loss: 0.5431 - val_accuracy: 0.7877\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.47671\n",
      "Epoch 25/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.5050 - accuracy: 0.8059 - val_loss: 0.5274 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.47671\n",
      "Epoch 26/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4915 - accuracy: 0.8132 - val_loss: 0.5270 - val_accuracy: 0.7963\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.47671\n",
      "Epoch 27/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4868 - accuracy: 0.8137 - val_loss: 0.5184 - val_accuracy: 0.8018\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.47671\n",
      "Epoch 28/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4789 - accuracy: 0.8132 - val_loss: 0.5143 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.47671\n",
      "Epoch 29/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4813 - accuracy: 0.8167 - val_loss: 0.5166 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.47671\n",
      "Epoch 30/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4684 - accuracy: 0.8193 - val_loss: 0.5114 - val_accuracy: 0.8081\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.47671\n",
      "Epoch 31/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4615 - accuracy: 0.8206 - val_loss: 0.4994 - val_accuracy: 0.8112\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.47671\n",
      "Epoch 32/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4544 - accuracy: 0.8199 - val_loss: 0.5018 - val_accuracy: 0.8152\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.47671\n",
      "Epoch 33/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4450 - accuracy: 0.8289 - val_loss: 0.5062 - val_accuracy: 0.8109\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.47671\n",
      "Epoch 34/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4437 - accuracy: 0.8273 - val_loss: 0.4906 - val_accuracy: 0.8175\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.47671\n",
      "Epoch 35/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4393 - accuracy: 0.8311 - val_loss: 0.4909 - val_accuracy: 0.8168\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.47671\n",
      "Epoch 36/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4366 - accuracy: 0.8339 - val_loss: 0.4888 - val_accuracy: 0.8223\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.47671\n",
      "Epoch 37/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4194 - accuracy: 0.8373 - val_loss: 0.4830 - val_accuracy: 0.8282\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.47671\n",
      "Epoch 38/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4188 - accuracy: 0.8418 - val_loss: 0.4867 - val_accuracy: 0.8223\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.47671\n",
      "Epoch 39/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4199 - accuracy: 0.8417 - val_loss: 0.4848 - val_accuracy: 0.8254\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.47671\n",
      "Epoch 40/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4059 - accuracy: 0.8457 - val_loss: 0.4738 - val_accuracy: 0.8282\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.47671 to 0.47384, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 41/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.4073 - accuracy: 0.8425 - val_loss: 0.4756 - val_accuracy: 0.8333\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.47384\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 9s 24ms/step - loss: 0.4011 - accuracy: 0.8449 - val_loss: 0.4751 - val_accuracy: 0.8313\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.47384\n",
      "Epoch 43/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3887 - accuracy: 0.8535 - val_loss: 0.4697 - val_accuracy: 0.8250\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.47384 to 0.46969, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 44/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3884 - accuracy: 0.8537 - val_loss: 0.4654 - val_accuracy: 0.8364\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.46969 to 0.46542, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 45/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3785 - accuracy: 0.8550 - val_loss: 0.4798 - val_accuracy: 0.8282\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.46542\n",
      "Epoch 46/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3704 - accuracy: 0.8624 - val_loss: 0.4660 - val_accuracy: 0.8396\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.46542\n",
      "Epoch 47/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3733 - accuracy: 0.8594 - val_loss: 0.4637 - val_accuracy: 0.8337\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.46542 to 0.46368, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 48/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3701 - accuracy: 0.8626 - val_loss: 0.4659 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.46368\n",
      "Epoch 49/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3711 - accuracy: 0.8572 - val_loss: 0.4624 - val_accuracy: 0.8360\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.46368 to 0.46236, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 50/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3642 - accuracy: 0.8648 - val_loss: 0.4636 - val_accuracy: 0.8329\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.46236\n",
      "Epoch 51/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3567 - accuracy: 0.8665 - val_loss: 0.4705 - val_accuracy: 0.8364\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.46236\n",
      "Epoch 52/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3502 - accuracy: 0.8663 - val_loss: 0.4615 - val_accuracy: 0.8415\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.46236 to 0.46146, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 53/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3483 - accuracy: 0.8668 - val_loss: 0.4601 - val_accuracy: 0.8419\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.46146 to 0.46006, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 54/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3487 - accuracy: 0.8693 - val_loss: 0.4702 - val_accuracy: 0.8392\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.46006\n",
      "Epoch 55/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3463 - accuracy: 0.8742 - val_loss: 0.4547 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.46006 to 0.45475, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 56/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3444 - accuracy: 0.8710 - val_loss: 0.4595 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.45475\n",
      "Epoch 57/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3406 - accuracy: 0.8730 - val_loss: 0.4690 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.45475\n",
      "Epoch 58/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3264 - accuracy: 0.8764 - val_loss: 0.4671 - val_accuracy: 0.8392\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.45475\n",
      "Epoch 59/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3322 - accuracy: 0.8739 - val_loss: 0.4584 - val_accuracy: 0.8403\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.45475\n",
      "Epoch 60/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3231 - accuracy: 0.8747 - val_loss: 0.4642 - val_accuracy: 0.8447\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.45475\n",
      "Epoch 61/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3151 - accuracy: 0.8823 - val_loss: 0.4625 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.45475\n",
      "Epoch 62/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3173 - accuracy: 0.8783 - val_loss: 0.4624 - val_accuracy: 0.8407\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.45475\n",
      "Epoch 63/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3188 - accuracy: 0.8801 - val_loss: 0.4672 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.45475\n",
      "Epoch 64/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3144 - accuracy: 0.8818 - val_loss: 0.4587 - val_accuracy: 0.8455\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.45475\n",
      "Epoch 65/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3089 - accuracy: 0.8870 - val_loss: 0.4686 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.45475\n",
      "Epoch 66/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3101 - accuracy: 0.8827 - val_loss: 0.4561 - val_accuracy: 0.8431\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.45475\n",
      "Epoch 67/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2990 - accuracy: 0.8865 - val_loss: 0.4747 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.45475\n",
      "Epoch 68/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3056 - accuracy: 0.8864 - val_loss: 0.4558 - val_accuracy: 0.8517\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.45475\n",
      "Epoch 69/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2985 - accuracy: 0.8894 - val_loss: 0.4547 - val_accuracy: 0.8525\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.45475 to 0.45469, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 70/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2965 - accuracy: 0.8855 - val_loss: 0.4516 - val_accuracy: 0.8537\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.45469 to 0.45160, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 71/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.3008 - accuracy: 0.8889 - val_loss: 0.4567 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.45160\n",
      "Epoch 72/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2892 - accuracy: 0.8939 - val_loss: 0.4621 - val_accuracy: 0.8525\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.45160\n",
      "Epoch 73/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2916 - accuracy: 0.8902 - val_loss: 0.4622 - val_accuracy: 0.8514\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.45160\n",
      "Epoch 74/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2850 - accuracy: 0.8943 - val_loss: 0.4551 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.45160\n",
      "Epoch 75/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2769 - accuracy: 0.8963 - val_loss: 0.4608 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.45160\n",
      "Epoch 76/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2679 - accuracy: 0.8990 - val_loss: 0.4611 - val_accuracy: 0.8612\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.45160\n",
      "Epoch 77/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2819 - accuracy: 0.8945 - val_loss: 0.4475 - val_accuracy: 0.8561\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.45160 to 0.44750, saving model to ../app/models/lstm_model.h5\n",
      "Epoch 78/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2781 - accuracy: 0.8963 - val_loss: 0.4624 - val_accuracy: 0.8635\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.44750\n",
      "Epoch 79/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2744 - accuracy: 0.8997 - val_loss: 0.4730 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.44750\n",
      "Epoch 80/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2601 - accuracy: 0.9025 - val_loss: 0.4627 - val_accuracy: 0.8584\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.44750\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2584 - accuracy: 0.9064 - val_loss: 0.4630 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.44750\n",
      "Epoch 82/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2669 - accuracy: 0.9004 - val_loss: 0.4621 - val_accuracy: 0.8557\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.44750\n",
      "Epoch 83/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2691 - accuracy: 0.9024 - val_loss: 0.4721 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.44750\n",
      "Epoch 84/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2686 - accuracy: 0.9025 - val_loss: 0.4667 - val_accuracy: 0.8584\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.44750\n",
      "Epoch 85/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2621 - accuracy: 0.9007 - val_loss: 0.4676 - val_accuracy: 0.8514\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.44750\n",
      "Epoch 86/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2495 - accuracy: 0.9068 - val_loss: 0.4592 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.44750\n",
      "Epoch 87/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2541 - accuracy: 0.9061 - val_loss: 0.4552 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.44750\n",
      "Epoch 88/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2540 - accuracy: 0.9068 - val_loss: 0.4506 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.44750\n",
      "Epoch 89/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2615 - accuracy: 0.9027 - val_loss: 0.4638 - val_accuracy: 0.8624\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.44750\n",
      "Epoch 90/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2453 - accuracy: 0.9057 - val_loss: 0.4585 - val_accuracy: 0.8643\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.44750\n",
      "Epoch 91/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2522 - accuracy: 0.9081 - val_loss: 0.4706 - val_accuracy: 0.8659\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.44750\n",
      "Epoch 92/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2487 - accuracy: 0.9090 - val_loss: 0.4517 - val_accuracy: 0.8632\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.44750\n",
      "Epoch 93/100\n",
      "371/371 [==============================] - 9s 25ms/step - loss: 0.2464 - accuracy: 0.9066 - val_loss: 0.4650 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.44750\n",
      "Epoch 94/100\n",
      "187/371 [==============>...............] - ETA: 4s - loss: 0.2407 - accuracy: 0.9158"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        callbacks=[checkpointer, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f673cf8b7f91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ошибка'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ошибка'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Ошибка')\n",
    "plt.ylabel('Ошибка')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.legend(['Обучающая выборка', 'Тестовая выборка'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Точность')\n",
    "plt.ylabel('Точность')\n",
    "plt.xlabel('Эпоха')\n",
    "plt.legend(['Обучающая выборка', 'Тестовая выборка'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(validate_csv_path,  index_col=None)\n",
    "\n",
    "y_valid = dataset.label.values\n",
    "X_valid = np.stack(dataset.vec.apply(convert_vec).values)\n",
    "\n",
    "X_valid = min_max_scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid,y_valid = shape_data(X_valid,y_valid,window)\n",
    "\n",
    "y_valid = tf.keras.utils.to_categorical(list(map(lbl_dict.get, y_valid)), num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../app/models/gru_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 6ms/step - loss: 23.7980 - accuracy: 0.3731\n",
      "CPU times: user 697 ms, sys: 61.5 ms, total: 759 ms\n",
      "Wall time: 598 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[23.79796028137207, 0.3731343150138855]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model_lstm = tf.keras.models.load_model('../app/models/lstm_model.h5')\n",
    "model_gru = tf.keras.models.load_model('../app/models/gru_model.h5')\n",
    "lstm_predict = np.argmax(model_lstm.predict(X_valid), 1)\n",
    "gru_predict = np.argmax(model_gru.predict(X_valid), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gru f1-score: 0.3520339713449763\n",
      "LSTM f1-score: 0.35029539354403627\n"
     ]
    }
   ],
   "source": [
    "print(\"Gru f1-score: {0}\".format(f1_score(np.argmax(y_valid, 1), lstm_predict, average='weighted')))\n",
    "print(\"LSTM f1-score: {0}\".format(f1_score(np.argmax(y_valid, 1), gru_predict, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
